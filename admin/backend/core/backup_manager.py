#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤‡ä»½ç®¡ç†å™¨ - æ ¸å¿ƒå¤‡ä»½å’Œæ¢å¤é€»è¾‘
"""

import os
import sys
import json
import uuid
import shutil
import hashlib
import zipfile
import asyncio
import sqlite3
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import aiofiles

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

class BackupManager:
    """å¤‡ä»½ç®¡ç†å™¨"""
    
    def __init__(self):
        self.backup_dir = Path("backups")
        self.temp_dir = Path("temp_backups")
        self.project_root = Path(__file__).parent.parent.parent.parent
        
        # åˆ›å»ºå¿…è¦ç›®å½•
        self.backup_dir.mkdir(exist_ok=True)
        self.temp_dir.mkdir(exist_ok=True)
        
        # å¤‡ä»½è·¯å¾„é…ç½®
        self.main_service_paths = {
            "database": self.project_root / "back" / "tasks.db",
            "uploads": self.project_root / "back" / "uploads",
            "outputs": self.project_root / "back" / "outputs",
            "workflows": self.project_root / "back" / "workflows",
            "thumbnails": self.project_root / "back" / "thumbnails",
            "config": self.project_root / "back" / "config"
        }
        
        self.admin_service_paths = {
            "database": self.project_root / "admin" / "backend" / "admin.db",
            "uploads": self.project_root / "admin" / "uploads",
            "outputs": self.project_root / "admin" / "outputs",
            "config": self.project_root / "admin" / "backend" / "config.py"
        }
        
        self.system_paths = {
            "docker_compose": self.project_root / "docker-compose.yml",
            "docker_compose_prod": self.project_root / "docker-compose.prod.yml",
            "env_production": self.project_root / "env.production",
            "nginx": self.project_root / "nginx"
        }

    async def create_backup(self, backup_type: str, backup_name: str, 
                          description: str = "", compression_level: int = 6, 
                          include_files: bool = True) -> str:
        """åˆ›å»ºå¤‡ä»½"""
        backup_id = str(uuid.uuid4())
        
        print(f"ğŸ”„ å¼€å§‹åˆ›å»ºå¤‡ä»½: {backup_name} ({backup_id})")
        print(f"ğŸ“‹ å¤‡ä»½ç±»å‹: {backup_type}")
        
        try:
            # éªŒè¯å¤‡ä»½ç±»å‹
            if backup_type not in ["full", "main_service", "admin_service"]:
                raise ValueError(f"æ— æ•ˆçš„å¤‡ä»½ç±»å‹: {backup_type}")
            
            # åˆ›å»ºä¸´æ—¶å¤‡ä»½ç›®å½•
            temp_backup_path = self.temp_dir / f"{backup_name}_{backup_id}"
            temp_backup_path.mkdir(parents=True, exist_ok=True)
            
            # åˆ›å»ºå¤‡ä»½å…ƒæ•°æ®
            metadata = {
                "backup_id": backup_id,
                "backup_name": backup_name,
                "backup_type": backup_type,
                "description": description,
                "created_at": datetime.now().isoformat(),
                "version": "1.0.0"
            }
            
            # æ‰§è¡Œå¤‡ä»½
            if backup_type == "full":
                await self._backup_main_service(temp_backup_path, include_files)
                await self._backup_admin_service(temp_backup_path)
                await self._backup_system_configs(temp_backup_path)
            elif backup_type == "main_service":
                await self._backup_main_service(temp_backup_path, include_files)
            elif backup_type == "admin_service":
                await self._backup_admin_service(temp_backup_path)
            
            # ä¿å­˜å…ƒæ•°æ®
            metadata_file = temp_backup_path / "backup_metadata.json"
            async with aiofiles.open(metadata_file, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(metadata, indent=2, ensure_ascii=False))
            
            # å‹ç¼©å¤‡ä»½
            archive_path = await self._compress_backup(temp_backup_path, backup_id, compression_level)
            
            # è®¡ç®—æ ¡éªŒå’Œ
            checksum = await self._calculate_checksum(archive_path)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            shutil.rmtree(temp_backup_path)
            
            print(f"âœ… å¤‡ä»½åˆ›å»ºæˆåŠŸ: {archive_path}")
            print(f"ğŸ“Š å¤‡ä»½å¤§å°: {archive_path.stat().st_size / (1024*1024):.2f} MB")
            print(f"ğŸ” æ ¡éªŒå’Œ: {checksum}")
            
            return backup_id
            
        except Exception as e:
            print(f"âŒ å¤‡ä»½åˆ›å»ºå¤±è´¥: {e}")
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_backup_path.exists():
                shutil.rmtree(temp_backup_path)
            raise e

    async def _backup_main_service(self, backup_path: Path, include_files: bool = True):
        """å¤‡ä»½ä¸»æœåŠ¡æ•°æ®"""
        print("ğŸ“¦ å¤‡ä»½ä¸»æœåŠ¡æ•°æ®...")
        
        main_service_dir = backup_path / "main_service"
        main_service_dir.mkdir(exist_ok=True)
        
        # å®šä¹‰æ–‡ä»¶ç›®å½•ï¼ˆå›¾ç‰‡ã€è§†é¢‘ã€ä¸Šä¼ æ–‡ä»¶ç­‰ï¼‰
        file_dirs = {'outputs', 'uploads', 'thumbnails'}
        
        for name, source_path in self.main_service_paths.items():
            # å¦‚æœè®¾ç½®äº†ä¸åŒ…å«æ–‡ä»¶ï¼Œä¸”å½“å‰ç›®å½•æ˜¯æ–‡ä»¶ç›®å½•ï¼Œåˆ™è·³è¿‡
            if not include_files and name in file_dirs:
                print(f"  â­ï¸ è·³è¿‡æ–‡ä»¶ç›®å½•: {name} (ä»…å¤‡ä»½æ•°æ®)")
                continue
                
            if source_path.exists():
                dest_path = main_service_dir / name
                
                if source_path.is_file():
                    dest_path.parent.mkdir(parents=True, exist_ok=True)
                    shutil.copy2(source_path, dest_path)
                    print(f"  âœ… å·²å¤‡ä»½æ–‡ä»¶: {name}")
                elif source_path.is_dir():
                    shutil.copytree(source_path, dest_path)
                    file_count = self._count_files(source_path)
                    size_mb = self._get_dir_size_mb(source_path)
                    print(f"  âœ… å·²å¤‡ä»½ç›®å½•: {name} ({file_count} ä¸ªæ–‡ä»¶, {size_mb:.2f} MB)")
            else:
                print(f"  âš ï¸ è·¯å¾„ä¸å­˜åœ¨ï¼Œè·³è¿‡: {name}")

    async def _backup_admin_service(self, backup_path: Path):
        """å¤‡ä»½AdminæœåŠ¡æ•°æ®"""
        print("ğŸ“¦ å¤‡ä»½AdminæœåŠ¡æ•°æ®...")
        
        admin_service_dir = backup_path / "admin_service"
        admin_service_dir.mkdir(exist_ok=True)
        
        for name, source_path in self.admin_service_paths.items():
            if source_path.exists():
                dest_path = admin_service_dir / name
                
                if source_path.is_file():
                    dest_path.parent.mkdir(parents=True, exist_ok=True)
                    shutil.copy2(source_path, dest_path)
                    print(f"  âœ… å·²å¤‡ä»½æ–‡ä»¶: {name}")
                elif source_path.is_dir():
                    shutil.copytree(source_path, dest_path)
                    print(f"  âœ… å·²å¤‡ä»½ç›®å½•: {name} ({self._count_files(source_path)} ä¸ªæ–‡ä»¶)")
            else:
                print(f"  âš ï¸ è·¯å¾„ä¸å­˜åœ¨ï¼Œè·³è¿‡: {name}")

    async def _backup_system_configs(self, backup_path: Path):
        """å¤‡ä»½ç³»ç»Ÿé…ç½®"""
        print("ğŸ“¦ å¤‡ä»½ç³»ç»Ÿé…ç½®...")
        
        system_dir = backup_path / "system"
        system_dir.mkdir(exist_ok=True)
        
        for name, source_path in self.system_paths.items():
            if source_path.exists():
                dest_path = system_dir / name
                
                if source_path.is_file():
                    shutil.copy2(source_path, dest_path)
                    print(f"  âœ… å·²å¤‡ä»½é…ç½®: {name}")
                elif source_path.is_dir():
                    shutil.copytree(source_path, dest_path)
                    print(f"  âœ… å·²å¤‡ä»½é…ç½®ç›®å½•: {name} ({self._count_files(source_path)} ä¸ªæ–‡ä»¶)")
            else:
                print(f"  âš ï¸ é…ç½®ä¸å­˜åœ¨ï¼Œè·³è¿‡: {name}")

    async def _compress_backup(self, source_path: Path, backup_id: str, compression_level: int) -> Path:
        """å‹ç¼©å¤‡ä»½æ–‡ä»¶"""
        print("ğŸ—œï¸ å‹ç¼©å¤‡ä»½æ–‡ä»¶...")
        
        archive_name = f"backup_{backup_id}.zip"
        archive_path = self.backup_dir / archive_name
        
        with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED, compresslevel=compression_level) as zipf:
            for root, dirs, files in os.walk(source_path):
                for file in files:
                    file_path = Path(root) / file
                    arcname = file_path.relative_to(source_path)
                    zipf.write(file_path, arcname)
        
        return archive_path

    async def _calculate_checksum(self, file_path: Path) -> str:
        """è®¡ç®—æ–‡ä»¶æ ¡éªŒå’Œ"""
        print("ğŸ” è®¡ç®—æ–‡ä»¶æ ¡éªŒå’Œ...")
        
        sha256_hash = hashlib.sha256()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                sha256_hash.update(chunk)
        
        return sha256_hash.hexdigest()

    async def restore_backup(self, backup_id: str, restore_type: str) -> bool:
        """æ¢å¤å¤‡ä»½"""
        print(f"ğŸ”„ å¼€å§‹æ¢å¤å¤‡ä»½: {backup_id}")
        print(f"ğŸ“‹ æ¢å¤ç±»å‹: {restore_type}")
        
        try:
            # æŸ¥æ‰¾å¤‡ä»½æ–‡ä»¶
            backup_file = self._find_backup_file(backup_id)
            if not backup_file:
                raise FileNotFoundError(f"å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {backup_id}")
            
            # éªŒè¯å¤‡ä»½æ–‡ä»¶
            if not await self._validate_backup(backup_file):
                raise ValueError("å¤‡ä»½æ–‡ä»¶æŸåæˆ–æ— æ•ˆ")
            
            # åˆ›å»ºä¸´æ—¶æ¢å¤ç›®å½•
            temp_restore_path = self.temp_dir / f"restore_{backup_id}"
            temp_restore_path.mkdir(exist_ok=True)
            
            try:
                # è§£å‹å¤‡ä»½æ–‡ä»¶
                await self._extract_backup(backup_file, temp_restore_path)
                
                # åœæ­¢æœåŠ¡ï¼ˆå¦‚æœéœ€è¦ï¼‰
                await self._stop_services_if_needed(restore_type)
                
                # æ‰§è¡Œæ¢å¤
                if restore_type == "full":
                    await self._restore_main_service(temp_restore_path)
                    await self._restore_admin_service(temp_restore_path)
                    await self._restore_system_configs(temp_restore_path)
                elif restore_type == "main_service":
                    await self._restore_main_service(temp_restore_path)
                elif restore_type == "admin_service":
                    await self._restore_admin_service(temp_restore_path)
                
                # é‡å¯æœåŠ¡ï¼ˆå¦‚æœéœ€è¦ï¼‰
                await self._restart_services_if_needed(restore_type)
                
                print("âœ… å¤‡ä»½æ¢å¤æˆåŠŸ")
                return True
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if temp_restore_path.exists():
                    shutil.rmtree(temp_restore_path)
                    
        except Exception as e:
            print(f"âŒ å¤‡ä»½æ¢å¤å¤±è´¥: {e}")
            raise e

    def _find_backup_file(self, backup_id: str) -> Optional[Path]:
        """æŸ¥æ‰¾å¤‡ä»½æ–‡ä»¶"""
        for file_path in self.backup_dir.glob(f"backup_{backup_id}.zip"):
            return file_path
        return None

    async def _validate_backup(self, backup_file: Path) -> bool:
        """éªŒè¯å¤‡ä»½æ–‡ä»¶"""
        try:
            with zipfile.ZipFile(backup_file, 'r') as zipf:
                # æ£€æŸ¥æ˜¯å¦æœ‰å…ƒæ•°æ®æ–‡ä»¶
                if 'backup_metadata.json' not in zipf.namelist():
                    return False
                
                # å°è¯•è¯»å–å…ƒæ•°æ®
                metadata_content = zipf.read('backup_metadata.json').decode('utf-8')
                metadata = json.loads(metadata_content)
                
                # éªŒè¯å¿…è¦å­—æ®µ
                required_fields = ['backup_id', 'backup_name', 'backup_type', 'created_at']
                for field in required_fields:
                    if field not in metadata:
                        return False
                
                return True
                
        except Exception as e:
            print(f"å¤‡ä»½éªŒè¯å¤±è´¥: {e}")
            return False

    async def _extract_backup(self, backup_file: Path, extract_path: Path):
        """è§£å‹å¤‡ä»½æ–‡ä»¶"""
        print("ğŸ“‚ è§£å‹å¤‡ä»½æ–‡ä»¶...")
        
        with zipfile.ZipFile(backup_file, 'r') as zipf:
            zipf.extractall(extract_path)

    async def _restore_main_service(self, restore_path: Path):
        """æ¢å¤ä¸»æœåŠ¡æ•°æ®"""
        print("ğŸ“¦ æ¢å¤ä¸»æœåŠ¡æ•°æ®...")
        
        main_service_dir = restore_path / "main_service"
        if not main_service_dir.exists():
            print("  âš ï¸ ä¸»æœåŠ¡æ•°æ®ä¸å­˜åœ¨ï¼Œè·³è¿‡æ¢å¤")
            return
        
        for name, dest_path in self.main_service_paths.items():
            source_path = main_service_dir / name
            
            if source_path.exists():
                if source_path.is_file():
                    dest_path.parent.mkdir(parents=True, exist_ok=True)
                    shutil.copy2(source_path, dest_path)
                    print(f"  âœ… å·²æ¢å¤æ–‡ä»¶: {name}")
                elif source_path.is_dir():
                    if dest_path.exists():
                        shutil.rmtree(dest_path)
                    shutil.copytree(source_path, dest_path)
                    print(f"  âœ… å·²æ¢å¤ç›®å½•: {name}")

    async def _restore_admin_service(self, restore_path: Path):
        """æ¢å¤AdminæœåŠ¡æ•°æ®"""
        print("ğŸ“¦ æ¢å¤AdminæœåŠ¡æ•°æ®...")
        
        admin_service_dir = restore_path / "admin_service"
        if not admin_service_dir.exists():
            print("  âš ï¸ AdminæœåŠ¡æ•°æ®ä¸å­˜åœ¨ï¼Œè·³è¿‡æ¢å¤")
            return
        
        for name, dest_path in self.admin_service_paths.items():
            source_path = admin_service_dir / name
            
            if source_path.exists():
                if source_path.is_file():
                    dest_path.parent.mkdir(parents=True, exist_ok=True)
                    shutil.copy2(source_path, dest_path)
                    print(f"  âœ… å·²æ¢å¤æ–‡ä»¶: {name}")
                elif source_path.is_dir():
                    if dest_path.exists():
                        shutil.rmtree(dest_path)
                    shutil.copytree(source_path, dest_path)
                    print(f"  âœ… å·²æ¢å¤ç›®å½•: {name}")

    async def _restore_system_configs(self, restore_path: Path):
        """æ¢å¤ç³»ç»Ÿé…ç½®"""
        print("ğŸ“¦ æ¢å¤ç³»ç»Ÿé…ç½®...")
        
        system_dir = restore_path / "system"
        if not system_dir.exists():
            print("  âš ï¸ ç³»ç»Ÿé…ç½®ä¸å­˜åœ¨ï¼Œè·³è¿‡æ¢å¤")
            return
        
        for name, dest_path in self.system_paths.items():
            source_path = system_dir / name
            
            if source_path.exists():
                if source_path.is_file():
                    shutil.copy2(source_path, dest_path)
                    print(f"  âœ… å·²æ¢å¤é…ç½®: {name}")
                elif source_path.is_dir():
                    if dest_path.exists():
                        shutil.rmtree(dest_path)
                    shutil.copytree(source_path, dest_path)
                    print(f"  âœ… å·²æ¢å¤é…ç½®ç›®å½•: {name}")

    async def _stop_services_if_needed(self, restore_type: str):
        """åœæ­¢ç›¸å…³æœåŠ¡"""
        print("â¸ï¸ åœæ­¢ç›¸å…³æœåŠ¡...")
        # è¿™é‡Œå¯ä»¥æ·»åŠ åœæ­¢æœåŠ¡çš„é€»è¾‘
        # æ ¹æ®ç”¨æˆ·è§„åˆ™ï¼Œéœ€è¦ç¡®è®¤åå†æ‰§è¡Œ
        print("  â„¹ï¸ æœåŠ¡åœæ­¢éœ€è¦ç®¡ç†å‘˜ç¡®è®¤")

    async def _restart_services_if_needed(self, restore_type: str):
        """é‡å¯ç›¸å…³æœåŠ¡"""
        print("â–¶ï¸ é‡å¯ç›¸å…³æœåŠ¡...")
        # è¿™é‡Œå¯ä»¥æ·»åŠ é‡å¯æœåŠ¡çš„é€»è¾‘
        # æ ¹æ®ç”¨æˆ·è§„åˆ™ï¼Œéœ€è¦ç¡®è®¤åå†æ‰§è¡Œ
        print("  â„¹ï¸ æœåŠ¡é‡å¯éœ€è¦ç®¡ç†å‘˜ç¡®è®¤")

    def _count_files(self, directory: Path) -> int:
        """ç»Ÿè®¡ç›®å½•ä¸­çš„æ–‡ä»¶æ•°é‡"""
        try:
            return sum(1 for _ in directory.rglob('*') if _.is_file())
        except:
            return 0
    
    def _get_dir_size_mb(self, path: Path) -> float:
        """è·å–ç›®å½•å¤§å°ï¼ˆMBï¼‰"""
        if path.is_file():
            return path.stat().st_size / (1024 * 1024)
        
        total_size = 0
        for file_path in path.rglob('*'):
            if file_path.is_file():
                try:
                    total_size += file_path.stat().st_size
                except (OSError, PermissionError):
                    continue
        
        return total_size / (1024 * 1024)

    async def list_backups(self, page: int = 1, limit: int = 20, backup_type: str = "all") -> Dict[str, Any]:
        """è·å–å¤‡ä»½åˆ—è¡¨"""
        backups = []
        
        for backup_file in self.backup_dir.glob("backup_*.zip"):
            try:
                # ä»æ–‡ä»¶åæå–backup_id
                backup_id = backup_file.stem.replace("backup_", "")
                
                # è¯»å–å¤‡ä»½å…ƒæ•°æ®
                with zipfile.ZipFile(backup_file, 'r') as zipf:
                    if 'backup_metadata.json' in zipf.namelist():
                        metadata_content = zipf.read('backup_metadata.json').decode('utf-8')
                        metadata = json.loads(metadata_content)
                        
                        # è¿‡æ»¤å¤‡ä»½ç±»å‹
                        if backup_type != "all" and metadata.get('backup_type') != backup_type:
                            continue
                        
                        backup_info = {
                            "backup_id": backup_id,
                            "backup_name": metadata.get('backup_name', ''),
                            "backup_type": metadata.get('backup_type', ''),
                            "file_path": str(backup_file),
                            "backup_size": backup_file.stat().st_size,
                            "status": "completed",
                            "description": metadata.get('description', ''),
                            "created_at": metadata.get('created_at', ''),
                            "checksum": None  # å¯ä»¥å•ç‹¬è®¡ç®—
                        }
                        
                        backups.append(backup_info)
                        
            except Exception as e:
                print(f"è¯»å–å¤‡ä»½ä¿¡æ¯å¤±è´¥ {backup_file}: {e}")
                continue
        
        # æŒ‰åˆ›å»ºæ—¶é—´æ’åº
        backups.sort(key=lambda x: x.get('created_at', ''), reverse=True)
        
        # åˆ†é¡µ
        total = len(backups)
        start = (page - 1) * limit
        end = start + limit
        page_backups = backups[start:end]
        
        return {
            "backups": page_backups,
            "total": total,
            "page": page,
            "limit": limit,
            "has_more": end < total
        }

    async def delete_backup(self, backup_id: str) -> bool:
        """åˆ é™¤å¤‡ä»½"""
        backup_file = self._find_backup_file(backup_id)
        if backup_file and backup_file.exists():
            backup_file.unlink()
            print(f"âœ… å·²åˆ é™¤å¤‡ä»½æ–‡ä»¶: {backup_file}")
            return True
        return False

    async def cleanup_old_backups(self, retention_days: int = 30):
        """æ¸…ç†è¿‡æœŸå¤‡ä»½"""
        print(f"ğŸ§¹ æ¸…ç† {retention_days} å¤©å‰çš„å¤‡ä»½...")
        
        cutoff_date = datetime.now() - timedelta(days=retention_days)
        deleted_count = 0
        
        for backup_file in self.backup_dir.glob("backup_*.zip"):
            try:
                file_modified = datetime.fromtimestamp(backup_file.stat().st_mtime)
                if file_modified < cutoff_date:
                    backup_file.unlink()
                    deleted_count += 1
                    print(f"  ğŸ—‘ï¸ å·²åˆ é™¤è¿‡æœŸå¤‡ä»½: {backup_file.name}")
                    
            except Exception as e:
                print(f"åˆ é™¤å¤‡ä»½å¤±è´¥ {backup_file}: {e}")
        
        print(f"âœ… æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {deleted_count} ä¸ªè¿‡æœŸå¤‡ä»½")
        return deleted_count
