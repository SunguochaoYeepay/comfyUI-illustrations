#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å·¥ä½œæµåˆå§‹åŒ–è„šæœ¬
ä»ä¸»æœåŠ¡çš„workflowsç›®å½•å¯¼å…¥æ‰€æœ‰å·¥ä½œæµJSONæ–‡ä»¶åˆ°ç®¡ç†åå°æ•°æ®åº“
"""

import json
import os
import sys
from pathlib import Path
from sqlalchemy.orm import Session
from database import SessionLocal, engine
import models

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def get_workflow_files():
    """è·å–æ‰€æœ‰å·¥ä½œæµJSONæ–‡ä»¶"""
    # ä¸»æœåŠ¡çš„workflowsç›®å½•è·¯å¾„
    main_workflows_dir = Path("../../back/workflows")
    
    if not main_workflows_dir.exists():
        print(f"âŒ ä¸»æœåŠ¡workflowsç›®å½•ä¸å­˜åœ¨: {main_workflows_dir}")
        return []
    
    workflow_files = []
    
    # é€’å½’æŸ¥æ‰¾æ‰€æœ‰JSONæ–‡ä»¶
    for json_file in main_workflows_dir.rglob("*.json"):
        if json_file.is_file():
            workflow_files.append(json_file)
    
    print(f"ğŸ“ æ‰¾åˆ° {len(workflow_files)} ä¸ªå·¥ä½œæµæ–‡ä»¶")
    return workflow_files

def load_workflow_json(file_path):
    """åŠ è½½å·¥ä½œæµJSONæ–‡ä»¶"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"âŒ åŠ è½½å·¥ä½œæµæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return None

def create_workflow_name(file_path):
    """æ ¹æ®æ–‡ä»¶è·¯å¾„åˆ›å»ºå·¥ä½œæµåç§°"""
    # è·å–ç›¸å¯¹è·¯å¾„
    relative_path = file_path.relative_to(Path("../../back/workflows"))
    
    # ç§»é™¤.jsonæ‰©å±•å
    name = relative_path.stem
    
    # æ›¿æ¢è·¯å¾„åˆ†éš”ç¬¦ä¸ºä¸‹åˆ’çº¿
    name = str(relative_path.parent / name).replace("/", "_").replace("\\", "_")
    
    # å¦‚æœåç§°å¤ªé•¿ï¼Œæˆªå–
    if len(name) > 80:
        name = name[:80]
    
    return name

def create_workflow_description(file_path, workflow_json):
    """åˆ›å»ºå·¥ä½œæµæè¿°"""
    # è·å–ç›¸å¯¹è·¯å¾„
    relative_path = file_path.relative_to(Path("../../back/workflows"))
    
    # åŸºç¡€æè¿°
    description = f"ä» {relative_path} å¯¼å…¥çš„å·¥ä½œæµ"
    
    # å°è¯•ä»å·¥ä½œæµä¸­æå–æ›´å¤šä¿¡æ¯
    if isinstance(workflow_json, dict):
        node_count = len(workflow_json)
        description += f"ï¼ŒåŒ…å« {node_count} ä¸ªèŠ‚ç‚¹"
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç‰¹å®šçš„èŠ‚ç‚¹ç±»å‹
        node_types = set()
        for node_data in workflow_json.values():
            if isinstance(node_data, dict) and "class_type" in node_data:
                node_types.add(node_data["class_type"])
        
        if node_types:
            description += f"ï¼Œä¸»è¦èŠ‚ç‚¹ç±»å‹: {', '.join(list(node_types)[:3])}"
    
    return description

def import_workflows():
    """å¯¼å…¥æ‰€æœ‰å·¥ä½œæµåˆ°æ•°æ®åº“"""
    print("ğŸš€ å¼€å§‹å¯¼å…¥å·¥ä½œæµ...")
    
    # åˆ›å»ºæ•°æ®åº“è¡¨
    models.Base.metadata.create_all(bind=engine)
    
    # è·å–æ•°æ®åº“ä¼šè¯
    db = SessionLocal()
    
    try:
        # è·å–æ‰€æœ‰å·¥ä½œæµæ–‡ä»¶
        workflow_files = get_workflow_files()
        
        if not workflow_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å·¥ä½œæµæ–‡ä»¶")
            return
        
        imported_count = 0
        skipped_count = 0
        
        for file_path in workflow_files:
            print(f"\nğŸ“„ å¤„ç†æ–‡ä»¶: {file_path}")
            
            # åŠ è½½JSONå†…å®¹
            workflow_json = load_workflow_json(file_path)
            if workflow_json is None:
                skipped_count += 1
                continue
            
            # åˆ›å»ºå·¥ä½œæµåç§°å’Œæè¿°
            name = create_workflow_name(file_path)
            description = create_workflow_description(file_path, workflow_json)
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨åŒåå·¥ä½œæµ
            existing_workflow = db.query(models.Workflow).filter(models.Workflow.name == name).first()
            if existing_workflow:
                print(f"â­ï¸  è·³è¿‡å·²å­˜åœ¨çš„å·¥ä½œæµ: {name}")
                skipped_count += 1
                continue
            
            # åˆ›å»ºå·¥ä½œæµè®°å½•
            workflow = models.Workflow(
                name=name,
                description=description,
                workflow_json=workflow_json
            )
            
            db.add(workflow)
            db.commit()
            db.refresh(workflow)
            
            print(f"âœ… å¯¼å…¥æˆåŠŸ: {name} (ID: {workflow.id})")
            imported_count += 1
        
        print(f"\nğŸ‰ å¯¼å…¥å®Œæˆ!")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   - æˆåŠŸå¯¼å…¥: {imported_count} ä¸ªå·¥ä½œæµ")
        print(f"   - è·³è¿‡: {skipped_count} ä¸ªå·¥ä½œæµ")
        print(f"   - æ€»è®¡å¤„ç†: {len(workflow_files)} ä¸ªæ–‡ä»¶")
        
    except Exception as e:
        print(f"âŒ å¯¼å…¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        db.rollback()
    finally:
        db.close()

def list_imported_workflows():
    """åˆ—å‡ºå·²å¯¼å…¥çš„å·¥ä½œæµ"""
    print("\nğŸ“‹ å·²å¯¼å…¥çš„å·¥ä½œæµåˆ—è¡¨:")
    
    db = SessionLocal()
    try:
        workflows = db.query(models.Workflow).all()
        
        if not workflows:
            print("   (æš‚æ— å·¥ä½œæµ)")
            return
        
        for workflow in workflows:
            node_count = len(workflow.workflow_json) if workflow.workflow_json else 0
            print(f"   - ID: {workflow.id}, åç§°: {workflow.name}")
            print(f"     æè¿°: {workflow.description}")
            print(f"     èŠ‚ç‚¹æ•°: {node_count}, åˆ›å»ºæ—¶é—´: {workflow.created_at}")
            print()
            
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å·¥ä½œæµåˆ—è¡¨å¤±è´¥: {e}")
    finally:
        db.close()

if __name__ == "__main__":
    print("ğŸ”§ YeePay AI å·¥ä½œæµåˆå§‹åŒ–å·¥å…·")
    print("=" * 50)
    
    # å¯¼å…¥å·¥ä½œæµ
    import_workflows()
    
    # åˆ—å‡ºå·²å¯¼å…¥çš„å·¥ä½œæµ
    list_imported_workflows()
    
    print("\nâœ¨ åˆå§‹åŒ–å®Œæˆ!")
