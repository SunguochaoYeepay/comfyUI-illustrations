#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å·¥ä½œæµæ–‡ä»¶ç®¡ç†å™¨
æ”¯æŒä»æ–‡ä»¶ç³»ç»ŸåŒæ­¥å·¥ä½œæµåˆ°æ•°æ®åº“ï¼Œä»¥åŠä»æ•°æ®åº“å¯¼å‡ºå·¥ä½œæµåˆ°æ–‡ä»¶
"""

import json
import os
import shutil
from pathlib import Path
from datetime import datetime
from sqlalchemy.orm import Session
from database import SessionLocal, engine
import models

class WorkflowFileManager:
    """å·¥ä½œæµæ–‡ä»¶ç®¡ç†å™¨"""
    
    def __init__(self, workflows_dir: str = None):
        """
        åˆå§‹åŒ–å·¥ä½œæµæ–‡ä»¶ç®¡ç†å™¨
        
        Args:
            workflows_dir: å·¥ä½œæµæ–‡ä»¶å­˜å‚¨ç›®å½•ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•ä¸‹çš„workflowsæ–‡ä»¶å¤¹
        """
        self.workflows_dir = Path(workflows_dir) if workflows_dir else Path("workflows")
        self.workflows_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºå­ç›®å½•
        self.subdirs = {
            'qwen': self.workflows_dir / 'qwen',
            'flux': self.workflows_dir / 'flux',
            'flux1': self.workflows_dir / 'flux1',
            'gemini': self.workflows_dir / 'gemini',
            'wan': self.workflows_dir / 'wan',
            'fusion': self.workflows_dir / 'fusion',
            'templates': self.workflows_dir / 'templates'
        }
        
        for subdir in self.subdirs.values():
            subdir.mkdir(exist_ok=True)
    
    def sync_from_main_service(self, main_workflows_dir: str = "../../back/workflows"):
        """
        ä»ä¸»æœåŠ¡åŒæ­¥å·¥ä½œæµæ–‡ä»¶
        
        Args:
            main_workflows_dir: ä¸»æœåŠ¡å·¥ä½œæµç›®å½•è·¯å¾„
        """
        print("ğŸ”„ ä»ä¸»æœåŠ¡åŒæ­¥å·¥ä½œæµæ–‡ä»¶...")
        
        main_dir = Path(main_workflows_dir)
        if not main_dir.exists():
            print(f"âŒ ä¸»æœåŠ¡å·¥ä½œæµç›®å½•ä¸å­˜åœ¨: {main_dir}")
            return
        
        # æ¸…ç©ºç›®æ ‡ç›®å½•
        if self.workflows_dir.exists():
            shutil.rmtree(self.workflows_dir)
            self.workflows_dir.mkdir(exist_ok=True)
            for subdir in self.subdirs.values():
                subdir.mkdir(exist_ok=True)
        
        # å¤åˆ¶æ‰€æœ‰JSONæ–‡ä»¶
        copied_count = 0
        for json_file in main_dir.rglob("*.json"):
            if json_file.is_file():
                # è®¡ç®—ç›¸å¯¹è·¯å¾„
                relative_path = json_file.relative_to(main_dir)
                
                # åˆ›å»ºç›®æ ‡è·¯å¾„
                target_path = self.workflows_dir / relative_path
                target_path.parent.mkdir(parents=True, exist_ok=True)
                
                # å¤åˆ¶æ–‡ä»¶
                shutil.copy2(json_file, target_path)
                print(f"ğŸ“„ å¤åˆ¶: {relative_path}")
                copied_count += 1
        
        print(f"âœ… åŒæ­¥å®Œæˆï¼Œå…±å¤åˆ¶ {copied_count} ä¸ªæ–‡ä»¶")
    
    def export_workflow_to_file(self, workflow_id: int, target_dir: str = None):
        """
        å°†æ•°æ®åº“ä¸­çš„å·¥ä½œæµå¯¼å‡ºä¸ºJSONæ–‡ä»¶
        
        Args:
            workflow_id: å·¥ä½œæµID
            target_dir: ç›®æ ‡ç›®å½•ï¼Œé»˜è®¤ä¸ºworkflowsç›®å½•
        """
        db = SessionLocal()
        try:
            workflow = db.query(models.Workflow).filter(models.Workflow.id == workflow_id).first()
            if not workflow:
                print(f"âŒ å·¥ä½œæµä¸å­˜åœ¨: ID {workflow_id}")
                return None
            
            # ç¡®å®šç›®æ ‡ç›®å½•
            if target_dir:
                target_path = Path(target_dir)
            else:
                target_path = self.workflows_dir
            
            target_path.mkdir(exist_ok=True)
            
            # ç”Ÿæˆæ–‡ä»¶å
            filename = f"{workflow.name}.json"
            file_path = target_path / filename
            
            # å†™å…¥æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(workflow.workflow_json, f, indent=2, ensure_ascii=False)
            
            print(f"ğŸ“„ å¯¼å‡ºå·¥ä½œæµ: {workflow.name} -> {file_path}")
            return file_path
            
        except Exception as e:
            print(f"âŒ å¯¼å‡ºå·¥ä½œæµå¤±è´¥: {e}")
            return None
        finally:
            db.close()
    
    def export_all_workflows(self, target_dir: str = None):
        """
        å¯¼å‡ºæ‰€æœ‰å·¥ä½œæµåˆ°æ–‡ä»¶
        
        Args:
            target_dir: ç›®æ ‡ç›®å½•ï¼Œé»˜è®¤ä¸ºworkflowsç›®å½•
        """
        print("ğŸ“¤ å¯¼å‡ºæ‰€æœ‰å·¥ä½œæµåˆ°æ–‡ä»¶...")
        
        db = SessionLocal()
        try:
            workflows = db.query(models.Workflow).all()
            
            if not workflows:
                print("âŒ æ•°æ®åº“ä¸­æ²¡æœ‰å·¥ä½œæµ")
                return
            
            # ç¡®å®šç›®æ ‡ç›®å½•
            if target_dir:
                target_path = Path(target_dir)
            else:
                target_path = self.workflows_dir
            
            target_path.mkdir(exist_ok=True)
            
            exported_count = 0
            for workflow in workflows:
                filename = f"{workflow.name}.json"
                file_path = target_path / filename
                
                try:
                    with open(file_path, 'w', encoding='utf-8') as f:
                        json.dump(workflow.workflow_json, f, indent=2, ensure_ascii=False)
                    
                    print(f"âœ… å¯¼å‡º: {workflow.name}")
                    exported_count += 1
                    
                except Exception as e:
                    print(f"âŒ å¯¼å‡ºå¤±è´¥ {workflow.name}: {e}")
            
            print(f"ğŸ‰ å¯¼å‡ºå®Œæˆï¼Œå…±å¯¼å‡º {exported_count} ä¸ªå·¥ä½œæµ")
            
        except Exception as e:
            print(f"âŒ å¯¼å‡ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        finally:
            db.close()
    
    def import_workflow_from_file(self, file_path: str, name: str = None, description: str = None):
        """
        ä»JSONæ–‡ä»¶å¯¼å…¥å·¥ä½œæµåˆ°æ•°æ®åº“
        
        Args:
            file_path: JSONæ–‡ä»¶è·¯å¾„
            name: å·¥ä½œæµåç§°ï¼Œé»˜è®¤ä¸ºæ–‡ä»¶å
            description: å·¥ä½œæµæè¿°
        """
        file_path = Path(file_path)
        if not file_path.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return None
        
        try:
            # åŠ è½½JSONå†…å®¹
            with open(file_path, 'r', encoding='utf-8') as f:
                workflow_json = json.load(f)
            
            # ç¡®å®šåç§°å’Œæè¿°
            if not name:
                name = file_path.stem
            
            if not description:
                description = f"ä»æ–‡ä»¶ {file_path.name} å¯¼å…¥çš„å·¥ä½œæµ"
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            db = SessionLocal()
            try:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                existing = db.query(models.Workflow).filter(models.Workflow.name == name).first()
                if existing:
                    print(f"â­ï¸  å·¥ä½œæµå·²å­˜åœ¨: {name}")
                    return existing
                
                # åˆ›å»ºæ–°å·¥ä½œæµ
                workflow = models.Workflow(
                    name=name,
                    description=description,
                    workflow_json=workflow_json
                )
                
                db.add(workflow)
                db.commit()
                db.refresh(workflow)
                
                print(f"âœ… å¯¼å…¥æˆåŠŸ: {name} (ID: {workflow.id})")
                return workflow
                
            except Exception as e:
                print(f"âŒ ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {e}")
                db.rollback()
                return None
            finally:
                db.close()
                
        except Exception as e:
            print(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def import_all_workflows_from_dir(self, source_dir: str = None):
        """
        ä»ç›®å½•å¯¼å…¥æ‰€æœ‰å·¥ä½œæµæ–‡ä»¶
        
        Args:
            source_dir: æºç›®å½•ï¼Œé»˜è®¤ä¸ºworkflowsç›®å½•
        """
        if source_dir:
            source_path = Path(source_dir)
        else:
            source_path = self.workflows_dir
        
        if not source_path.exists():
            print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {source_path}")
            return
        
        print(f"ğŸ“¥ ä»ç›®å½•å¯¼å…¥å·¥ä½œæµ: {source_path}")
        
        imported_count = 0
        skipped_count = 0
        
        # æŸ¥æ‰¾æ‰€æœ‰JSONæ–‡ä»¶
        for json_file in source_path.rglob("*.json"):
            if json_file.is_file():
                print(f"\nğŸ“„ å¤„ç†æ–‡ä»¶: {json_file}")
                
                # ç”Ÿæˆåç§°å’Œæè¿°
                relative_path = json_file.relative_to(source_path)
                name = str(relative_path).replace("/", "_").replace("\\", "_").replace(".json", "")
                description = f"ä» {relative_path} å¯¼å…¥çš„å·¥ä½œæµ"
                
                # å¯¼å…¥å·¥ä½œæµ
                workflow = self.import_workflow_from_file(json_file, name, description)
                if workflow:
                    imported_count += 1
                else:
                    skipped_count += 1
        
        print(f"\nğŸ‰ å¯¼å…¥å®Œæˆ!")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   - æˆåŠŸå¯¼å…¥: {imported_count} ä¸ªå·¥ä½œæµ")
        print(f"   - è·³è¿‡: {skipped_count} ä¸ªå·¥ä½œæµ")
    
    def list_workflow_files(self):
        """åˆ—å‡ºå·¥ä½œæµæ–‡ä»¶"""
        print("ğŸ“‹ å·¥ä½œæµæ–‡ä»¶åˆ—è¡¨:")
        
        if not self.workflows_dir.exists():
            print("   (ç›®å½•ä¸å­˜åœ¨)")
            return
        
        file_count = 0
        for json_file in self.workflows_dir.rglob("*.json"):
            if json_file.is_file():
                relative_path = json_file.relative_to(self.workflows_dir)
                file_size = json_file.stat().st_size
                print(f"   - {relative_path} ({file_size} bytes)")
                file_count += 1
        
        if file_count == 0:
            print("   (æ²¡æœ‰æ‰¾åˆ°JSONæ–‡ä»¶)")
        else:
            print(f"\n   æ€»è®¡: {file_count} ä¸ªæ–‡ä»¶")
    
    def cleanup_orphaned_files(self):
        """æ¸…ç†å­¤ç«‹çš„æ–‡ä»¶ï¼ˆæ•°æ®åº“ä¸­æ²¡æœ‰å¯¹åº”è®°å½•çš„æ–‡ä»¶ï¼‰"""
        print("ğŸ§¹ æ¸…ç†å­¤ç«‹çš„å·¥ä½œæµæ–‡ä»¶...")
        
        db = SessionLocal()
        try:
            # è·å–æ•°æ®åº“ä¸­æ‰€æœ‰å·¥ä½œæµåç§°
            workflows = db.query(models.Workflow).all()
            db_names = {wf.name for wf in workflows}
            
            # æ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿä¸­çš„æ–‡ä»¶
            orphaned_files = []
            for json_file in self.workflows_dir.rglob("*.json"):
                if json_file.is_file():
                    file_name = json_file.stem
                    if file_name not in db_names:
                        orphaned_files.append(json_file)
            
            if orphaned_files:
                print(f"å‘ç° {len(orphaned_files)} ä¸ªå­¤ç«‹æ–‡ä»¶:")
                for file_path in orphaned_files:
                    print(f"   - {file_path}")
                
                # è¯¢é—®æ˜¯å¦åˆ é™¤
                response = input("\næ˜¯å¦åˆ é™¤è¿™äº›å­¤ç«‹æ–‡ä»¶? (y/N): ")
                if response.lower() == 'y':
                    for file_path in orphaned_files:
                        file_path.unlink()
                        print(f"ğŸ—‘ï¸  åˆ é™¤: {file_path}")
                    print("âœ… æ¸…ç†å®Œæˆ")
                else:
                    print("â­ï¸  è·³è¿‡æ¸…ç†")
            else:
                print("âœ… æ²¡æœ‰å‘ç°å­¤ç«‹æ–‡ä»¶")
                
        except Exception as e:
            print(f"âŒ æ¸…ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        finally:
            db.close()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ YeePay AI å·¥ä½œæµæ–‡ä»¶ç®¡ç†å™¨")
    print("=" * 50)
    
    manager = WorkflowFileManager()
    
    while True:
        print("\nğŸ“‹ å¯ç”¨æ“ä½œ:")
        print("1. ä»ä¸»æœåŠ¡åŒæ­¥å·¥ä½œæµæ–‡ä»¶")
        print("2. ä»æ–‡ä»¶å¯¼å…¥å·¥ä½œæµåˆ°æ•°æ®åº“")
        print("3. ä»æ•°æ®åº“å¯¼å‡ºå·¥ä½œæµåˆ°æ–‡ä»¶")
        print("4. å¯¼å‡ºæ‰€æœ‰å·¥ä½œæµ")
        print("5. åˆ—å‡ºå·¥ä½œæµæ–‡ä»¶")
        print("6. æ¸…ç†å­¤ç«‹æ–‡ä»¶")
        print("7. é€€å‡º")
        
        choice = input("\nè¯·é€‰æ‹©æ“ä½œ (1-7): ").strip()
        
        if choice == '1':
            manager.sync_from_main_service()
        elif choice == '2':
            source_dir = input("è¯·è¾“å…¥æºç›®å½•è·¯å¾„ (å›è½¦ä½¿ç”¨é»˜è®¤): ").strip()
            if not source_dir:
                source_dir = None
            manager.import_all_workflows_from_dir(source_dir)
        elif choice == '3':
            workflow_id = input("è¯·è¾“å…¥å·¥ä½œæµID: ").strip()
            try:
                workflow_id = int(workflow_id)
                manager.export_workflow_to_file(workflow_id)
            except ValueError:
                print("âŒ æ— æ•ˆçš„å·¥ä½œæµID")
        elif choice == '4':
            manager.export_all_workflows()
        elif choice == '5':
            manager.list_workflow_files()
        elif choice == '6':
            manager.cleanup_orphaned_files()
        elif choice == '7':
            print("ğŸ‘‹ å†è§!")
            break
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")

if __name__ == "__main__":
    main()
