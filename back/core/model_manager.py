#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹ç®¡ç†å™¨
è´Ÿè´£ç®¡ç†ä¸åŒçš„åŸºç¡€æ¨¡å‹ï¼ˆFluxã€Qwenç­‰ï¼‰
"""

import json
import os
from pathlib import Path
from typing import Dict, Any, List, Optional
from enum import Enum

from config.settings import COMFYUI_MAIN_OUTPUT_DIR, COMFYUI_MODELS_DIR


class ModelType(Enum):
    """æ¨¡å‹ç±»å‹æšä¸¾"""
    FLUX = "flux"
    QWEN = "qwen"
    WAN = "wan" # Added WAN model type
    FLUX1 = "flux1" # Added FLUX1 model type
    GEMINI = "gemini" # Added GEMINI model type


class ModelConfig:
    """æ¨¡å‹é…ç½®ç±»"""
    
    def __init__(self, model_type: ModelType, name: str, display_name: str, 
                 unet_file: str, clip_file: str, vae_file: str, 
                 template_path: str, description: str = ""):
        self.model_type = model_type
        self.name = name
        self.display_name = display_name
        self.unet_file = unet_file
        self.clip_file = clip_file
        self.vae_file = vae_file
        self.template_path = template_path
        self.description = description
        self.available = self._check_availability()
    
    def _check_availability(self) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å¯ç”¨"""
        try:
            # APIæ¨¡å‹ï¼ˆå¦‚Geminiï¼‰ä¸éœ€è¦æœ¬åœ°æ–‡ä»¶ï¼Œç›´æ¥è¿”å›å¯ç”¨
            if self.model_type == ModelType.GEMINI:
                print(f"âœ… APIæ¨¡å‹ {self.name} å¯ç”¨")
                return True
            
            # ä½¿ç”¨ç»Ÿä¸€é…ç½®çš„æ¨¡å‹ç›®å½•è·¯å¾„
            model_dir = COMFYUI_MODELS_DIR
            
            # åœ¨Dockerç¯å¢ƒä¸­ï¼Œå¦‚æœæ¨¡å‹ç›®å½•ä¸å­˜åœ¨ï¼Œå‡è®¾æ¨¡å‹é€šè¿‡æŒ‚è½½å¯ç”¨
            if not model_dir.exists():
                print(f"âš ï¸ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨ï¼Œå‡è®¾æ¨¡å‹ {self.name} é€šè¿‡æŒ‚è½½å¯ç”¨: {model_dir}")
                return True
            
            # æ ¹æ®æ¨¡å‹ç±»å‹ç¡®å®šæ–‡ä»¶è·¯å¾„
            if self.model_type == ModelType.FLUX:
                unet_path = model_dir / "checkpoints" / self.unet_file
                clip_path = model_dir / "clip" / self.clip_file
                vae_path = model_dir / "vae" / self.vae_file
            elif self.model_type == ModelType.QWEN:
                unet_path = model_dir / "diffusion_models" / self.unet_file
                clip_path = model_dir / "text_encoders" / self.clip_file
                vae_path = model_dir / "vae" / self.vae_file
            elif self.model_type == ModelType.WAN: # Added WAN model type
                unet_path = model_dir / "diffusion_models" / self.unet_file
                clip_path = model_dir / "text_encoders" / self.clip_file
                vae_path = model_dir / "vae" / self.vae_file
            elif self.model_type == ModelType.FLUX1: # Added FLUX1 model type
                unet_path = model_dir / "unet" / self.unet_file # ä½¿ç”¨unetç›®å½•
                clip_path = model_dir / "clip" / self.clip_file
                vae_path = model_dir / "vae" / self.vae_file
            else:
                # é»˜è®¤ä½¿ç”¨checkpointsç›®å½•
                unet_path = model_dir / "checkpoints" / self.unet_file
                clip_path = model_dir / "clip" / self.clip_file
                vae_path = model_dir / "vae" / self.vae_file
            
            unet_exists = unet_path.exists()
            clip_exists = clip_path.exists()
            vae_exists = vae_path.exists()
            
            # è°ƒè¯•ä¿¡æ¯ï¼ˆç”Ÿäº§ç¯å¢ƒå¯æ³¨é‡Šæ‰ï¼‰
            # print(f"ğŸ” æ£€æŸ¥æ¨¡å‹ {self.name} æ–‡ä»¶:")
            # print(f"  - UNet: {unet_path} - {'âœ…' if unet_exists else 'âŒ'}")
            # print(f"  - CLIP: {clip_path} - {'âœ…' if clip_exists else 'âŒ'}")
            # print(f"  - VAE: {vae_path} - {'âœ…' if vae_exists else 'âŒ'}")
            
            return (unet_exists and clip_exists and vae_exists)
        except Exception:
            return False
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "type": self.model_type.value,
            "name": self.name,
            "display_name": self.display_name,
            "unet_file": self.unet_file,
            "clip_file": self.clip_file,
            "vae_file": self.vae_file,
            "description": self.description,
            "available": self.available
        }


class ModelManager:
    """æ¨¡å‹ç®¡ç†å™¨"""
    
    def __init__(self):
        self.models: Dict[str, ModelConfig] = {}
        self._init_models()
    
    def _init_models(self):
        """åˆå§‹åŒ–æ¨¡å‹é…ç½®"""
        # Fluxæ¨¡å‹é…ç½®
        flux_config = ModelConfig(
            model_type=ModelType.FLUX,
            name="flux1-dev",
            display_name="Flux Kontext",
            unet_file="flux1-dev-kontext_fp8_scaled.safetensors",
            clip_file="clip_l.safetensors",  # åŒCLIPæ¶æ„
            vae_file="ae.safetensors",
            template_path="flux_kontext_dev_basic.json",
            description="Flux Kontextå¼€å‘ç‰ˆæœ¬ï¼Œæ”¯æŒé«˜è´¨é‡å›¾åƒç”Ÿæˆ"
        )
        
        # Qwenæ¨¡å‹é…ç½®ï¼ˆæ”¯æŒå•å›¾å’Œå¤šå›¾èåˆï¼‰
        qwen_config = ModelConfig(
            model_type=ModelType.QWEN,
            name="qwen-image",
            display_name="Qwen",
            unet_file="qwen_image_fp8_e4m3fn.safetensors",  # åœ¨diffusion_modelsç›®å½•
            clip_file="qwen_2.5_vl_7b_fp8_scaled.safetensors",  # åœ¨text_encodersç›®å½•
            vae_file="qwen_image_vae.safetensors",  # åœ¨vaeç›®å½•
            template_path="workflows/qwen_image_generation_workflow.json",  # é»˜è®¤å•å›¾å·¥ä½œæµ
            description="åƒé—®å›¾åƒæ¨¡å‹ï¼Œæ”¯æŒå•å›¾ç”Ÿæˆå’Œå¤šå›¾èåˆ"
        )
        
        # Wan2.2è§†é¢‘æ¨¡å‹é…ç½®
        wan_config = ModelConfig(
            model_type=ModelType.WAN,
            name="wan2.2-video",
            display_name="Wan2.2 è§†é¢‘",
            unet_file="wan2.2_i2v_high_noise_14B_fp8_scaled.safetensors",  # åœ¨diffusion_modelsç›®å½•
            clip_file="umt5_xxl_fp8_e4m3fn_scaled.safetensors",  # åœ¨text_encodersç›®å½•
            vae_file="wan_2.1_vae.safetensors",  # åœ¨vaeç›®å½•
            template_path="workflows/wan2.2_video_generation_workflow.json",  # ä½¿ç”¨workflowsç›®å½•ä¸‹çš„æ ‡å‡†å·¥ä½œæµ
            description="Wan2.2å›¾åƒåˆ°è§†é¢‘æ¨¡å‹ï¼Œæ”¯æŒé«˜è´¨é‡è§†é¢‘ç”Ÿæˆ"
        )
        
        # Flux1åŸºç¡€æ¨¡å‹é…ç½®
        flux1_config = ModelConfig(
            model_type=ModelType.FLUX1,  # Flux1åŸºç¡€æ¨¡å‹ç±»å‹
            name="flux1",
            display_name="Flux1åŸºç¡€æ¨¡å‹",
            unet_file="FLUX.1-FP16-dev.sft",  # åŸºç¡€æ¨¡å‹æ–‡ä»¶
            clip_file="clip_l.safetensors",
            vae_file="ae.safetensors",
            template_path="workflows/flux1_vector_workflow.json",
            description="Flux1åŸºç¡€æ¨¡å‹ï¼Œæ”¯æŒå¤šç§å·¥ä½œæµï¼Œå¯é…ç½®ä¸åŒLoRAï¼Œè¾“å‡ºé«˜è´¨é‡å›¾åƒ"
        )
        
        # Google Gemini æ¨¡å‹é…ç½®
        gemini_config = ModelConfig(
            model_type=ModelType.GEMINI,
            name="gemini-image",
            display_name="Nano Banana",
            unet_file="",  # Gemini ä½¿ç”¨ APIï¼Œä¸éœ€è¦æœ¬åœ°æ–‡ä»¶
            clip_file="",
            vae_file="",
            template_path="workflows/google/api_google_gemini_image.json",
            description="Google Geminå›¾åƒç¼–è¾‘&èåˆï¼Œæ”¯æŒæ— å›¾ã€1å›¾ã€2å›¾çš„æ™ºèƒ½åˆæˆ"
        )
        
        self.models[flux_config.name] = flux_config
        self.models[qwen_config.name] = qwen_config
        self.models[wan_config.name] = wan_config
        self.models[flux1_config.name] = flux1_config
        self.models[gemini_config.name] = gemini_config
    
    def get_available_models(self) -> List[Dict[str, Any]]:
        """è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨ï¼ŒæŒ‰ç…§æŒ‡å®šé¡ºåºæ’åº"""
        # å®šä¹‰æ¨¡å‹æ˜¾ç¤ºé¡ºåº
        model_order = ['qwen-image', 'gemini-image', 'flux1-dev', 'flux1', 'wan2.2-video']
        
        available_models = []
        ordered_models = []
        
        # æŒ‰ç…§æŒ‡å®šé¡ºåºæ·»åŠ æ¨¡å‹
        for model_name in model_order:
            if model_name in self.models and self.models[model_name].available:
                ordered_models.append(self.models[model_name].to_dict())
        
        # æ·»åŠ å…¶ä»–å¯ç”¨æ¨¡å‹ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        for model in self.models.values():
            if model.available and model.name not in model_order:
                ordered_models.append(model.to_dict())
        
        return ordered_models
    
    def get_model_config(self, model_name: str) -> Optional[ModelConfig]:
        """è·å–æŒ‡å®šæ¨¡å‹çš„é…ç½®"""
        return self.models.get(model_name)
    
    def get_default_model(self) -> ModelConfig:
        """è·å–é»˜è®¤æ¨¡å‹ï¼ˆQwenï¼‰"""
        return self.models["qwen-image"]
    
    def is_model_available(self, model_name: str) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨"""
        model = self.models.get(model_name)
        return model is not None and model.available
    
    def get_model_template_path(self, model_name: str) -> Optional[str]:
        """è·å–æ¨¡å‹çš„å·¥ä½œæµæ¨¡æ¿è·¯å¾„"""
        model = self.models.get(model_name)
        if model and model.available:
            return model.template_path
        return None
    
    def get_available_loras(self) -> List[Dict[str, Any]]:
        """è·å–å¯ç”¨çš„ LoRA æ–‡ä»¶åˆ—è¡¨"""
        try:
            # ä½¿ç”¨ç»Ÿä¸€é…ç½®çš„ LoRA ç›®å½•è·¯å¾„
            from config.settings import COMFYUI_LORAS_DIR
            lora_dir = COMFYUI_LORAS_DIR
            
            if not lora_dir.exists():
                return []
            
            loras = []
            for file_path in lora_dir.iterdir():
                if file_path.is_file() and file_path.suffix.lower() in ['.safetensors', '.ckpt', '.pt']:
                    loras.append({
                        "name": file_path.name,
                        "path": str(file_path),
                        "size": file_path.stat().st_size,
                        "type": file_path.suffix.lower()
                    })
            
            return loras
        except Exception as e:
            print(f"Error getting LoRAs: {e}")
            return []


# å…¨å±€æ¨¡å‹ç®¡ç†å™¨å®ä¾‹
model_manager = ModelManager()


def get_available_models() -> List[Dict[str, Any]]:
    """è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
    return model_manager.get_available_models()


def get_model_config(model_name: str) -> Optional[ModelConfig]:
    """è·å–æŒ‡å®šæ¨¡å‹çš„é…ç½®"""
    return model_manager.get_model_config(model_name)


def get_default_model() -> ModelConfig:
    """è·å–é»˜è®¤æ¨¡å‹"""
    return model_manager.get_default_model()


def is_model_available(model_name: str) -> bool:
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨"""
    return model_manager.is_model_available(model_name)


def get_available_loras() -> List[Dict[str, Any]]:
    """è·å–å¯ç”¨çš„ LoRA æ–‡ä»¶åˆ—è¡¨"""
    return model_manager.get_available_loras()
