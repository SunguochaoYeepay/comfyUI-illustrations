#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å·¥ä½œæµæ¨¡æ¿ç®¡ç†å™¨
è´Ÿè´£åˆ›å»ºå’Œè‡ªå®šä¹‰Flux Kontextå·¥ä½œæµ
"""

import json
import random
from pathlib import Path
from typing import Any, Dict

from config.settings import (
    TARGET_IMAGE_WIDTH, TARGET_IMAGE_HEIGHT, 
    DEFAULT_STEPS, DEFAULT_COUNT, COMFYUI_MAIN_OUTPUT_DIR
)


class WorkflowTemplate:
    """å·¥ä½œæµæ¨¡æ¿ç®¡ç†å™¨ï¼Œè´Ÿè´£åˆ›å»ºå’Œè‡ªå®šä¹‰Flux Kontextå·¥ä½œæµ"""
    
    def __init__(self, template_path: str):
        """åˆå§‹åŒ–å·¥ä½œæµæ¨¡æ¿
        
        Args:
            template_path: æ¨¡æ¿æ–‡ä»¶è·¯å¾„
        """
        try:
            with open(template_path, 'r', encoding='utf-8') as f:
                self.template = json.load(f)
        except FileNotFoundError:
            raise FileNotFoundError(f"å·¥ä½œæµæ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {template_path}")
        except json.JSONDecodeError:
            raise ValueError(f"å·¥ä½œæµæ¨¡æ¿æ–‡ä»¶æ ¼å¼é”™è¯¯: {template_path}")
    
    def customize_workflow(self, reference_image_path: str, description: str, parameters: Dict[str, Any]):
        """è‡ªå®šä¹‰å·¥ä½œæµå‚æ•°"""
        # åˆ›å»ºä¸€ä¸ªç®€åŒ–çš„Flux Kontextå·¥ä½œæµï¼Œé¿å…åŸå§‹æ¨¡æ¿çš„å¤æ‚èŠ‚ç‚¹è¿æ¥é—®é¢˜
        
        workflow = {
            "6": {
                "inputs": {
                    "text": description,
                    "clip": ["38", 0]
                },
                "class_type": "CLIPTextEncode",
                "_meta": {"title": "CLIPæ–‡æœ¬ç¼–ç å™¨"}
            },
            "8": {
                "inputs": {
                    "samples": ["31", 0],
                    "vae": ["39", 0]
                },
                "class_type": "VAEDecode",
                "_meta": {"title": "VAEè§£ç "}
            },
            "31": {
                "inputs": {
                    "seed": parameters.get("seed", random.randint(1, 2**32 - 1)),
                    "steps": parameters.get("steps", DEFAULT_STEPS),
                    "cfg": 1,
                    "sampler_name": "euler",
                    "scheduler": "simple",
                    "denoise": 1,
                    "batch_size": parameters.get("count", DEFAULT_COUNT),
                    "model": ["37", 0],
                    "positive": ["35", 0],
                    "negative": ["135", 0],
                    "latent_image": ["124", 0]
                },
                "class_type": "KSampler",
                "_meta": {"title": "Ké‡‡æ ·å™¨"}
            },
            "35": {
                "inputs": {
                    "guidance": 2.5,
                    "conditioning": ["177", 0]
                },
                "class_type": "FluxGuidance",
                "_meta": {"title": "Fluxå¼•å¯¼"}
            },
            "37": {
                "inputs": {
                    "unet_name": "flux1-dev-kontext_fp8_scaled.safetensors",
                    "weight_dtype": "default"
                },
                "class_type": "UNETLoader",
                "_meta": {"title": "UNETåŠ è½½å™¨"}
            },
            "38": {
                "inputs": {
                    "clip_name1": "clip_l.safetensors",
                    "clip_name2": "t5xxl_fp8_e4m3fn_scaled.safetensors",
                    "type": "flux",
                    "device": "default"
                },
                "class_type": "DualCLIPLoader",
                "_meta": {"title": "åŒCLIPåŠ è½½å™¨"}
            },
            "39": {
                "inputs": {
                    "vae_name": "ae.safetensors"
                },
                "class_type": "VAELoader",
                "_meta": {"title": "VAEåŠ è½½å™¨"}
            },
            "42": {
                "inputs": {
                    "width": TARGET_IMAGE_WIDTH,
                    "height": TARGET_IMAGE_HEIGHT,
                    "batch_size": 1,
                    "color": 0
                },
                "class_type": "EmptyImage",
                "_meta": {"title": "ç©ºå›¾åƒ"}
            },
            "124": {
                "inputs": {
                    "pixels": ["42", 0],
                    "vae": ["39", 0]
                },
                "class_type": "VAEEncode",
                "_meta": {"title": "VAEç¼–ç "}
            },
            "135": {
                "inputs": {
                    "conditioning": ["6", 0]
                },
                "class_type": "ConditioningZeroOut",
                "_meta": {"title": "æ¡ä»¶é›¶åŒ–"}
            },
            "136": {
                "inputs": {
                    "filename_prefix": "yeepay/yeepay",
                    "images": ["8", 0],
                    "save_all": True
                },
                "class_type": "SaveImage",
                "_meta": {"title": "ä¿å­˜å›¾åƒ"}
            },
            "177": {
                "inputs": {
                    "conditioning": ["6", 0],
                    "latent": ["124", 0]
                },
                "class_type": "ReferenceLatent",
                "_meta": {"title": "ReferenceLatent"}
            }
        }
        
        print(f"âœ… åˆ›å»ºç®€åŒ–å·¥ä½œæµï¼ŒåŒ…å« {len(workflow)} ä¸ªèŠ‚ç‚¹")
        print(f"ğŸ“‹ å·¥ä½œæµèŠ‚ç‚¹: {list(workflow.keys())}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å‚è€ƒå›¾
        has_reference_image = reference_image_path and reference_image_path.strip() and not reference_image_path.endswith('blank.png') and reference_image_path != ""
        
        if has_reference_image:
            print("æ£€æµ‹åˆ°å‚è€ƒå›¾ï¼Œä½¿ç”¨å‚è€ƒå›¾æ¨¡å¼")
            # æ›´æ–°å‚è€ƒå›¾åƒè·¯å¾„ - å°†ä¸Šä¼ çš„å›¾åƒå¤åˆ¶åˆ°ComfyUIè¾“å‡ºç›®å½•å¹¶ä½¿ç”¨[output]åç¼€
            container_path = Path(reference_image_path)
            # ç»Ÿä¸€è·¯å¾„åˆ†éš”ç¬¦ï¼Œç¡®ä¿èƒ½æ­£ç¡®åŒ¹é…
            normalized_path = str(container_path).replace('\\', '/')
            if normalized_path.startswith('uploads/'):
                # å°†ä¸Šä¼ çš„å›¾åƒå‹ç¼©åˆ°512x512å¹¶å¤åˆ¶åˆ°ComfyUIè¾“å‡ºç›®å½•
                import shutil
                from PIL import Image
                import io
                
                source_file = Path(reference_image_path)
                dest_file = COMFYUI_MAIN_OUTPUT_DIR / source_file.name
                
                try:
                    # ä½¿ç”¨PILå‹ç¼©å›¾åƒåˆ°512x512
                    with Image.open(source_file) as img:
                        # è½¬æ¢ä¸ºRGBæ¨¡å¼ï¼ˆå¦‚æœéœ€è¦ï¼‰
                        if img.mode != 'RGB':
                            img = img.convert('RGB')
                        
                        # å‹ç¼©åˆ°512x512ï¼Œä¿æŒå®½é«˜æ¯”
                        img.thumbnail((TARGET_IMAGE_WIDTH, TARGET_IMAGE_HEIGHT), Image.Resampling.LANCZOS)
                        
                        # åˆ›å»º512x512çš„ç™½è‰²èƒŒæ™¯
                        background = Image.new('RGB', (TARGET_IMAGE_WIDTH, TARGET_IMAGE_HEIGHT), (255, 255, 255))
                        
                        # å°†å‹ç¼©åçš„å›¾åƒå±…ä¸­æ”¾ç½®
                        offset = ((TARGET_IMAGE_WIDTH - img.width) // 2, (TARGET_IMAGE_HEIGHT - img.height) // 2)
                        background.paste(img, offset)
                        
                        # ä¿å­˜å‹ç¼©åçš„å›¾åƒ
                        background.save(dest_file, 'PNG')
                    
                    print(f"âœ… å‚è€ƒå›¾å‹ç¼©åˆ°512x512å¹¶ä¿å­˜æˆåŠŸ: {source_file} -> {dest_file}")
                except Exception as e:
                    print(f"âŒ å‚è€ƒå›¾å‹ç¼©å¤±è´¥: {e}")
                    print(f"ğŸ“ æºæ–‡ä»¶: {source_file}")
                    print(f"ğŸ“ ç›®æ ‡æ–‡ä»¶: {dest_file}")
                    raise Exception(f"æ— æ³•å‹ç¼©å‚è€ƒå›¾åƒåˆ°{TARGET_IMAGE_WIDTH}x{TARGET_IMAGE_HEIGHT}: {e}")
                
                # ä½¿ç”¨æ–‡ä»¶ååŠ ä¸Š[output]åç¼€
                image_filename = f"{source_file.name} [output]"
                print(f"è®¾ç½®LoadImageOutputå›¾åƒè·¯å¾„: {image_filename}")
                
                # æ·»åŠ LoadImageOutputèŠ‚ç‚¹
                workflow["142"] = {
                    "inputs": {
                        "image": image_filename,
                        "refresh": "refresh"
                    },
                    "class_type": "LoadImageOutput",
                    "_meta": {"title": "åŠ è½½å›¾åƒï¼ˆæ¥è‡ªè¾“å‡ºï¼‰"}
                }
                
                # ä½¿ç”¨ImageScaleèŠ‚ç‚¹æ›¿ä»£FluxKontextImageScaleï¼Œå¼ºåˆ¶å›ºå®šå°ºå¯¸
                workflow["42"] = {
                    "inputs": {
                        "image": ["142", 0],
                        "width": TARGET_IMAGE_WIDTH,
                        "height": TARGET_IMAGE_HEIGHT,
                        "crop": "disabled",
                        "upscale_method": "lanczos",
                        "downscale_method": "area"
                    },
                    "class_type": "ImageScale",
                    "_meta": {"title": "å›¾åƒç¼©æ”¾"}
                }
                
                # æ›´æ–°VAEEncodeèŠ‚ç‚¹ä½¿ç”¨FluxKontextImageScaleçš„è¾“å‡º
                workflow["124"]["inputs"]["pixels"] = ["42", 0]
                
                print(f"âœ… é…ç½®å‚è€ƒå›¾æ¨¡å¼å·¥ä½œæµ")
            else:
                print(f"ä½¿ç”¨åŸå§‹è·¯å¾„: {reference_image_path}")
        else:
            print("æœªæ£€æµ‹åˆ°å‚è€ƒå›¾ï¼Œä½¿ç”¨æ— å‚è€ƒå›¾æ¨¡å¼")
            print(f"âœ… é…ç½®æ— å‚è€ƒå›¾æ¨¡å¼å·¥ä½œæµ")
        
        # æ›´æ–°ç”Ÿæˆå‚æ•°
        if parameters.get("steps"):
            workflow["31"]["inputs"]["steps"] = parameters["steps"]
        
        # æ›´æ–°CFGå‚æ•°ï¼ˆå¦‚æœæä¾›ï¼‰
        if parameters.get("cfg"):
            workflow["31"]["inputs"]["cfg"] = parameters["cfg"]
        
        # æ›´æ–°Guidanceå‚æ•°ï¼ˆå¦‚æœæä¾›ï¼‰
        if parameters.get("guidance"):
            workflow["35"]["inputs"]["guidance"] = parameters["guidance"]
        
        # å¤„ç†å›¾åƒå°ºå¯¸ - æ°¸è¿œä½¿ç”¨512x512
        target_width = TARGET_IMAGE_WIDTH
        target_height = TARGET_IMAGE_HEIGHT
        
        # æ— è®ºæ˜¯å¦æœ‰å‚è€ƒå›¾ï¼Œéƒ½ä½¿ç”¨å›ºå®šçš„512x512å°ºå¯¸
        if "42" in workflow and "inputs" in workflow["42"]:
            workflow["42"]["inputs"]["width"] = target_width
            workflow["42"]["inputs"]["height"] = target_height
            print(f"è®¾ç½®ç”Ÿæˆå›¾ç‰‡å°ºå¯¸ä¸º: {target_width}x{target_height} (å›ºå®šå°ºå¯¸)")
        
        # å¤„ç†ç”Ÿæˆæ•°é‡
        count = parameters.get("count", 1)
        print(f"ç”Ÿæˆæ•°é‡: {count}")
        # è®¾ç½®KSamplerçš„batch_sizeå‚æ•°
        if count > 1:
            workflow["31"]["inputs"]["batch_size"] = count
            print(f"è®¾ç½®batch_sizeä¸º: {count}")
            # ç¡®ä¿SaveImageèŠ‚ç‚¹çš„save_allå‚æ•°ä¸ºtrue
            if "136" in workflow and "inputs" in workflow["136"]:
                workflow["136"]["inputs"]["save_all"] = True
                print(f"è®¾ç½®SaveImageèŠ‚ç‚¹çš„save_allå‚æ•°ä¸ºtrueï¼Œç¡®ä¿ä¿å­˜æ‰€æœ‰æ‰¹æ¬¡å›¾ç‰‡")
        else:
            # ç¡®ä¿å•å¼ å›¾ç‰‡æ—¶batch_sizeä¸º1
            workflow["31"]["inputs"]["batch_size"] = 1
        
        # è®¾ç½®SaveImageèŠ‚ç‚¹çš„æ–‡ä»¶åå‰ç¼€ä¸ºyeepayï¼Œç”¨äºåŒºåˆ†é¡¹ç›®
        if "136" in workflow and "inputs" in workflow["136"]:
            workflow["136"]["inputs"]["filename_prefix"] = "yeepay/yeepay"
            print(f"è®¾ç½®SaveImageæ–‡ä»¶åå‰ç¼€ä¸º: yeepay/yeepay")
        
        # å¤„ç†ç§å­å‚æ•°
        if parameters.get("seed"):
            workflow["31"]["inputs"]["seed"] = parameters["seed"]
            print(f"ä½¿ç”¨æŒ‡å®šç§å­: {parameters['seed']}")
        else:
            # ç”Ÿæˆéšæœºç§å­
            seed = random.randint(1, 2**32 - 1)
            workflow["31"]["inputs"]["seed"] = seed
            print(f"ä½¿ç”¨éšæœºç§å­: {seed}")
        
        print(f"å·¥ä½œæµå‚æ•°æ›´æ–°å®Œæˆ: æè¿°='{description[:50]}...', æ­¥æ•°={workflow['31']['inputs']['steps']}, CFG={workflow['31']['inputs']['cfg']}, å¼•å¯¼={workflow['35']['inputs']['guidance']}")
        
        return workflow
