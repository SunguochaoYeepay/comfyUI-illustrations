#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Fluxå·¥ä½œæµå®ç°
ä¸“é—¨å¤„ç†Flux Kontextæ¨¡å‹çš„å·¥ä½œæµåˆ›å»º
"""

import random
from typing import Any, Dict

from config.settings import (
    TARGET_IMAGE_WIDTH, TARGET_IMAGE_HEIGHT, 
    DEFAULT_STEPS, DEFAULT_COUNT
)

from .base_workflow import BaseWorkflow


class FluxWorkflow(BaseWorkflow):
    """Fluxå·¥ä½œæµåˆ›å»ºå™¨"""
    
    def create_workflow(self, reference_image_path: str, description: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºFluxå·¥ä½œæµ
        
        Args:
            reference_image_path: å‚è€ƒå›¾åƒè·¯å¾„
            description: å›¾åƒæè¿°
            parameters: ç”Ÿæˆå‚æ•°
            
        Returns:
            Fluxå·¥ä½œæµå­—å…¸
        """
        print(f"ğŸ¨ åˆ›å»ºFluxå·¥ä½œæµ: {self.model_config.display_name}")
        
        # éªŒè¯å‚æ•°
        validated_params = self._validate_parameters(parameters)
        
        # å¤„ç†å‚è€ƒå›¾åƒ
        processed_image_path = self._process_reference_image(reference_image_path)
        
        # ä»æ•°æ®åº“åŠ è½½åŸºç¡€å·¥ä½œæµ
        workflow = self._load_workflow_template()
        
        # æ›´æ–°åŸºç¡€æ¨¡å‹
        workflow = self._update_base_model(workflow, validated_params)
        
        # æ¸…ç†æ— æ•ˆçš„å›¾åƒå¼•ç”¨èŠ‚ç‚¹
        workflow = self._clean_invalid_image_nodes(workflow)
        
        # å¤„ç†LoRAé…ç½®
        loras = validated_params.get("loras", [])
        if loras:
            workflow = self._add_lora_nodes(workflow, loras, description)
        
        # å¤„ç†å‚è€ƒå›¾åƒ
        if processed_image_path:
            workflow = self._add_reference_image_nodes(workflow, processed_image_path)
        
        # æ›´æ–°æœ€ç»ˆå‚æ•°
        workflow = self._update_final_parameters(workflow, validated_params)
        
        print(f"âœ… Fluxå·¥ä½œæµåˆ›å»ºå®Œæˆï¼ŒåŒ…å« {len(workflow)} ä¸ªèŠ‚ç‚¹")
        return workflow
    
    def _update_base_model(self, workflow: Dict[str, Any], parameters: Dict[str, Any]) -> Dict[str, Any]:
        """æ›´æ–°åŸºç¡€æ¨¡å‹"""
        base_model = parameters.get("base_model", self.model_config.unet_file)
        
        if "37" in workflow:  # UNETLoaderèŠ‚ç‚¹
            workflow["37"]["inputs"]["unet_name"] = base_model
            print(f"ğŸ”„ æ›´æ–°åŸºç¡€æ¨¡å‹: {base_model}")
        
        return workflow
    
    def _create_base_workflow(self, description: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºåŸºç¡€Fluxå·¥ä½œæµ"""
        workflow = {
            "6": {
                "inputs": {
                    "text": description,
                    "clip": ["38", 0]
                },
                "class_type": "CLIPTextEncode",
                "_meta": {"title": "CLIPæ–‡æœ¬ç¼–ç å™¨"}
            },
            "8": {
                "inputs": {
                    "samples": ["31", 0],
                    "vae": ["39", 0]
                },
                "class_type": "VAEDecode",
                "_meta": {"title": "VAEè§£ç "}
            },
            "31": {
                "inputs": {
                    "seed": parameters.get("seed", random.randint(1, 2**32 - 1)),
                    "steps": parameters.get("steps", DEFAULT_STEPS),
                    "cfg": 1,
                    "sampler_name": "euler",
                    "scheduler": "simple",
                    "denoise": 1,
                    "batch_size": parameters.get("count", DEFAULT_COUNT),
                    "model": ["37", 0],
                    "positive": ["35", 0],
                    "negative": ["135", 0],
                    "latent_image": ["124", 0]
                },
                "class_type": "KSampler",
                "_meta": {"title": "Ké‡‡æ ·å™¨"}
            },
            "35": {
                "inputs": {
                    "guidance": 2.5,
                    "conditioning": ["177", 0]
                },
                "class_type": "FluxGuidance",
                "_meta": {"title": "Fluxå¼•å¯¼"}
            },
            "37": {
                "inputs": {
                    "unet_name": self.model_config.unet_file,
                    "weight_dtype": "default"
                },
                "class_type": "UNETLoader",
                "_meta": {"title": "UNETåŠ è½½å™¨"}
            },
            "38": {
                "inputs": {
                    "clip_name1": "clip_l.safetensors",
                    "clip_name2": "t5xxl_fp8_e4m3fn_scaled.safetensors",
                    "type": "flux",
                    "device": "default"
                },
                "class_type": "DualCLIPLoader",
                "_meta": {"title": "åŒCLIPåŠ è½½å™¨"}
            },
            "39": {
                "inputs": {
                    "vae_name": "ae.safetensors"
                },
                "class_type": "VAELoader",
                "_meta": {"title": "VAEåŠ è½½å™¨"}
            },
            "42": {
                "inputs": {
                    "width": TARGET_IMAGE_WIDTH,
                    "height": TARGET_IMAGE_HEIGHT,
                    "batch_size": 1,
                    "color": 0
                },
                "class_type": "EmptyImage",
                "_meta": {"title": "ç©ºå›¾åƒ"}
            },
            "124": {
                "inputs": {
                    "pixels": ["42", 0],
                    "vae": ["39", 0]
                },
                "class_type": "VAEEncode",
                "_meta": {"title": "VAEç¼–ç "}
            },
            "135": {
                "inputs": {
                    "conditioning": ["6", 0]
                },
                "class_type": "ConditioningZeroOut",
                "_meta": {"title": "æ¡ä»¶é›¶åŒ–"}
            },
            "136": {
                "inputs": {
                    "filename_prefix": "yeepay/yeepay",
                    "images": ["8", 0],
                    "save_all": True
                },
                "class_type": "SaveImage",
                "_meta": {"title": "ä¿å­˜å›¾åƒ"}
            },
            "177": {
                "inputs": {
                    "conditioning": ["6", 0],
                    "latent": ["124", 0]
                },
                "class_type": "ReferenceLatent",
                "_meta": {"title": "ReferenceLatent"}
            }
        }
        
        return workflow
    
    def _add_lora_nodes(self, workflow: Dict[str, Any], loras: list, description: str) -> Dict[str, Any]:
        """æ·»åŠ LoRAèŠ‚ç‚¹"""
        processed_loras = self._process_loras(loras)
        
        if not processed_loras:
            return workflow
        
        print(f"ğŸ¨ æ£€æµ‹åˆ° {len(processed_loras)} ä¸ªLoRAé…ç½®")
        
        current_model_node = "37"  # UNETLoader
        current_clip_node = "38"   # DualCLIPLoader
        
        for i, lora_config in enumerate(processed_loras):
            lora_node_id = str(50 + i)  # 50, 51, 52, 53
            lora_name = lora_config["name"]
            strength_model = lora_config["strength_model"]
            strength_clip = lora_config["strength_clip"]
            trigger_word = lora_config["trigger_word"]
            
            print(f"ğŸ¨ æ·»åŠ LoRA {i+1}: {lora_name} (UNET: {strength_model}, CLIP: {strength_clip})")
            
            # æ·»åŠ LoRAèŠ‚ç‚¹
            workflow[lora_node_id] = {
                "inputs": {
                    "model": [current_model_node, 0],
                    "clip": [current_clip_node, 0],
                    "lora_name": lora_name,
                    "strength_model": strength_model,
                    "strength_clip": strength_clip
                },
                "class_type": "LoraLoader",
                "_meta": {"title": f"LoRAåŠ è½½å™¨{i+1}"}
            }
            
            # æ›´æ–°å½“å‰èŠ‚ç‚¹å¼•ç”¨
            current_model_node = lora_node_id
            current_clip_node = lora_node_id
            
            # æ·»åŠ è§¦å‘è¯
            if trigger_word and trigger_word not in description:
                description = f"{trigger_word}, {description}"
                print(f"ğŸ”¤ æ·»åŠ è§¦å‘è¯: {trigger_word}")
        
        # æ›´æ–°è¿æ¥
        workflow["31"]["inputs"]["model"] = [current_model_node, 0]
        workflow["6"]["inputs"]["clip"] = [current_clip_node, 1]
        workflow["6"]["inputs"]["text"] = description
        
        print(f"âœ… LoRAèŠ‚ç‚¹è¿æ¥å®Œæˆ: UNET -> {current_model_node}, CLIP -> {current_clip_node}")
        return workflow
    
    def _add_reference_image_nodes(self, workflow: Dict[str, Any], image_path: str) -> Dict[str, Any]:
        """æ·»åŠ å‚è€ƒå›¾åƒèŠ‚ç‚¹"""
        print("æ£€æµ‹åˆ°å‚è€ƒå›¾ï¼Œä½¿ç”¨å‚è€ƒå›¾æ¨¡å¼")
        
        # æ·»åŠ LoadImageOutputèŠ‚ç‚¹
        comfyui_path = self._convert_path_for_comfyui(image_path)
        workflow["142"] = {
            "inputs": {
                "image": comfyui_path,
                "refresh": "refresh"
            },
            "class_type": "LoadImageOutput",
            "_meta": {"title": "åŠ è½½å›¾åƒï¼ˆæ¥è‡ªè¾“å‡ºï¼‰"}
        }
        
        # æ›´æ–°ImageScaleèŠ‚ç‚¹
        workflow["42"] = {
            "inputs": {
                "image": ["142", 0],
                "width": TARGET_IMAGE_WIDTH,
                "height": TARGET_IMAGE_HEIGHT,
                "crop": "disabled",
                "upscale_method": "lanczos",
                "downscale_method": "area"
            },
            "class_type": "ImageScale",
            "_meta": {"title": "å›¾åƒç¼©æ”¾"}
        }
        
        # æ›´æ–°VAEEncodeèŠ‚ç‚¹
        workflow["124"]["inputs"]["pixels"] = ["42", 0]
        
        print(f"âœ… é…ç½®å‚è€ƒå›¾æ¨¡å¼å·¥ä½œæµ")
        return workflow
    
    def _update_final_parameters(self, workflow: Dict[str, Any], parameters: Dict[str, Any]) -> Dict[str, Any]:
        """æ›´æ–°æœ€ç»ˆå‚æ•°ï¼ˆå®‰å…¨æ›´æ–°ï¼Œæ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å­˜åœ¨ï¼‰"""
        # æ›´æ–°ç”Ÿæˆå‚æ•° - æ£€æŸ¥èŠ‚ç‚¹31æ˜¯å¦å­˜åœ¨
        if "31" in workflow:
            if parameters.get("steps"):
                workflow["31"]["inputs"]["steps"] = parameters["steps"]
            
            if parameters.get("cfg"):
                workflow["31"]["inputs"]["cfg"] = parameters["cfg"]
            
            # å¤„ç†ç”Ÿæˆæ•°é‡
            count = parameters.get("count", 1)
            workflow["31"]["inputs"]["batch_size"] = count
        
        # æ›´æ–°å¼•å¯¼å‚æ•° - æ£€æŸ¥èŠ‚ç‚¹35æ˜¯å¦å­˜åœ¨
        if "35" in workflow and parameters.get("guidance"):
            workflow["35"]["inputs"]["guidance"] = parameters["guidance"]
        
        # å¤„ç†ç”Ÿæˆæ•°é‡ - æ£€æŸ¥èŠ‚ç‚¹136æ˜¯å¦å­˜åœ¨
        count = parameters.get("count", 1)
        if count > 1 and "136" in workflow:
            workflow["136"]["inputs"]["save_all"] = True
            print(f"è®¾ç½®batch_sizeä¸º: {count}")
        
        # è®¾ç½®ç§å­ - æ£€æŸ¥èŠ‚ç‚¹31æ˜¯å¦å­˜åœ¨
        if "31" in workflow:
            if parameters.get("seed"):
                workflow["31"]["inputs"]["seed"] = parameters["seed"]
                print(f"ä½¿ç”¨æŒ‡å®šç§å­: {parameters['seed']}")
            else:
                seed = random.randint(1, 2**32 - 1)
                workflow["31"]["inputs"]["seed"] = seed
                print(f"ä½¿ç”¨éšæœºç§å­: {seed}")
        
        # æ›´æ–°å›¾åƒå°ºå¯¸
        size_str = parameters.get("size", "1024x1024")
        try:
            width, height = map(int, size_str.split('x'))
        except (ValueError, AttributeError):
            # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å°ºå¯¸
            width, height = 1024, 1024
            print(f"âš ï¸ å°ºå¯¸è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å°ºå¯¸: {width}x{height}")
        
        # æ›´æ–°èŠ‚ç‚¹42ï¼ˆFluxKontextImageScaleï¼‰çš„å°ºå¯¸é…ç½®
        if "42" in workflow:
            workflow["42"]["inputs"]["width"] = width
            workflow["42"]["inputs"]["height"] = height
            print(f"âœ… æ›´æ–°Fluxå›¾åƒå°ºå¯¸: {width}x{height}")
        
        # å®‰å…¨åœ°æ‰“å°å‚æ•°ä¿¡æ¯
        steps_info = workflow["31"]["inputs"]["steps"] if "31" in workflow else "N/A"
        cfg_info = workflow["31"]["inputs"]["cfg"] if "31" in workflow else "N/A"
        guidance_info = workflow["35"]["inputs"]["guidance"] if "35" in workflow else "N/A"
        print(f"å·¥ä½œæµå‚æ•°æ›´æ–°å®Œæˆ: æ­¥æ•°={steps_info}, CFG={cfg_info}, å¼•å¯¼={guidance_info}, å°ºå¯¸={width}x{height}")
        return workflow
    
    def _convert_path_for_comfyui(self, image_path: str) -> str:
        """è½¬æ¢Windowsè·¯å¾„ä¸ºComfyUIå…¼å®¹çš„è·¯å¾„æ ¼å¼
        
        Args:
            image_path: åŸå§‹å›¾åƒè·¯å¾„
            
        Returns:
            ComfyUIå…¼å®¹çš„è·¯å¾„æ ¼å¼
        """
        import os
        from config.settings import COMFYUI_INPUT_DIR
        
        # è·å–æ–‡ä»¶åï¼ˆä¸åŒ…å«è·¯å¾„ï¼‰
        filename = os.path.basename(image_path)
        
        # ComfyUIæœŸæœ›çš„æ˜¯ç›¸å¯¹äºè¾“å…¥ç›®å½•çš„æ–‡ä»¶å
        comfyui_path = filename
        
        print(f"ğŸ”„ è·¯å¾„è½¬æ¢: {image_path} -> {comfyui_path}")
        print(f"ğŸ“ ComfyUIè¾“å…¥ç›®å½•: {COMFYUI_INPUT_DIR}")
        return comfyui_path
    
    def _load_workflow_template(self) -> Dict[str, Any]:
        """ä»æ•°æ®åº“åŠ è½½å·¥ä½œæµæ¨¡æ¿"""
        import sqlite3
        import json
        from pathlib import Path
        
        # æ•°æ®åº“è·¯å¾„
        db_path = Path(__file__).parent.parent.parent.parent / "admin" / "admin.db"
        
        if not db_path.exists():
            print(f"âš ï¸ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨å†…ç½®æ¨¡æ¿: {db_path}")
            return self._create_base_workflow("", {})
        
        # ä»æ•°æ®åº“åŠ è½½å·¥ä½œæµ
        conn = sqlite3.connect(str(db_path))
        cursor = conn.cursor()
        
        try:
            cursor.execute("SELECT workflow_json FROM workflows WHERE name = ?", ("flux1_flux_kontext_dev_basic_2",))
            result = cursor.fetchone()
            
            if not result:
                print(f"âš ï¸ æ•°æ®åº“ä¸­æœªæ‰¾åˆ°Fluxå·¥ä½œæµï¼Œä½¿ç”¨å†…ç½®æ¨¡æ¿")
                return self._create_base_workflow("", {})
            
            workflow = json.loads(result[0])
            print(f"âœ… ä»æ•°æ®åº“åŠ è½½Fluxå·¥ä½œæµæ¨¡æ¿: flux1_flux_kontext_dev_basic_2")
            return workflow
            
        except Exception as e:
            print(f"âŒ ä»æ•°æ®åº“åŠ è½½Fluxå·¥ä½œæµå¤±è´¥: {e}ï¼Œä½¿ç”¨å†…ç½®æ¨¡æ¿")
            return self._create_base_workflow("", {})
        finally:
            conn.close()
    
    def _clean_invalid_image_nodes(self, workflow: Dict[str, Any]) -> Dict[str, Any]:
        """æ¸…ç†æ— æ•ˆçš„å›¾åƒå¼•ç”¨èŠ‚ç‚¹ï¼ˆä¿å®ˆæ¸…ç†ç­–ç•¥ï¼‰"""
        # éœ€è¦æ¸…ç†çš„èŠ‚ç‚¹IDåˆ—è¡¨
        invalid_nodes = ["142", "147"]  # æ ¹æ®é”™è¯¯ä¿¡æ¯ä¸­çš„èŠ‚ç‚¹ID
        
        # åªåˆ é™¤æ— æ•ˆçš„å›¾åƒå¼•ç”¨èŠ‚ç‚¹ï¼Œä¸åˆ é™¤ä¾èµ–èŠ‚ç‚¹
        for node_id in invalid_nodes:
            if node_id in workflow:
                node = workflow[node_id]
                # æ£€æŸ¥æ˜¯å¦æ˜¯LoadImageOutputèŠ‚ç‚¹ä¸”å¼•ç”¨äº†æ— æ•ˆæ–‡ä»¶
                if (node.get("class_type") == "LoadImageOutput" and 
                    "image" in node.get("inputs", {})):
                    image_path = node["inputs"]["image"]
                    # å¦‚æœå¼•ç”¨äº†ä¸å­˜åœ¨çš„è¾“å‡ºæ–‡ä»¶ï¼Œç§»é™¤è¿™ä¸ªèŠ‚ç‚¹
                    if "[output]" in image_path:
                        print(f"ğŸ§¹ æ¸…ç†æ— æ•ˆçš„å›¾åƒå¼•ç”¨èŠ‚ç‚¹ {node_id}: {image_path}")
                        del workflow[node_id]
        
        # æ¸…ç†å¼•ç”¨å·²åˆ é™¤èŠ‚ç‚¹çš„è¾“å…¥ï¼Œä½†ä¸åˆ é™¤èŠ‚ç‚¹æœ¬èº«
        for node_id, node in workflow.items():
            if "inputs" in node:
                for input_name, input_value in node["inputs"].items():
                    # æ£€æŸ¥æ˜¯å¦å¼•ç”¨äº†å·²åˆ é™¤çš„èŠ‚ç‚¹
                    if isinstance(input_value, list) and len(input_value) >= 1:
                        referenced_node = str(input_value[0])
                        if referenced_node in invalid_nodes:
                            print(f"ğŸ§¹ æ¸…ç†èŠ‚ç‚¹ {node_id} ä¸­å¯¹å·²åˆ é™¤èŠ‚ç‚¹ {referenced_node} çš„å¼•ç”¨")
                            # å°†å¼•ç”¨è®¾ç½®ä¸ºNoneæˆ–ç©ºå€¼ï¼Œè€Œä¸æ˜¯åˆ é™¤æ•´ä¸ªèŠ‚ç‚¹
                            node["inputs"][input_name] = None
        
        # ä¿®å¤èŠ‚ç‚¹42çš„è¿æ¥ - FluxKontextImageScaleéœ€è¦ä¸€ä¸ªå›¾åƒè¾“å…¥
        if "42" in workflow:
            # æ£€æŸ¥èŠ‚ç‚¹42çš„ç±»å‹
            if workflow["42"].get("class_type") == "FluxKontextImageScale":
                # æ£€æŸ¥èŠ‚ç‚¹42æ˜¯å¦å·²ç»æœ‰æœ‰æ•ˆçš„å›¾åƒè¾“å…¥
                if "image" not in workflow["42"]["inputs"] or workflow["42"]["inputs"]["image"] is None:
                    # æ·»åŠ ä¸€ä¸ªæ–°çš„EmptyImageèŠ‚ç‚¹
                    workflow["200"] = {
                        "inputs": {
                            "width": 1024,
                            "height": 1024,
                            "batch_size": 1,
                            "color": 0
                        },
                        "class_type": "EmptyImage",
                        "_meta": {"title": "ç©ºå›¾åƒ"}
                    }
                    # å°†èŠ‚ç‚¹42è¿æ¥åˆ°æ–°çš„EmptyImageèŠ‚ç‚¹
                    workflow["42"]["inputs"]["image"] = ["200", 0]
                    print("âœ… ä¸ºèŠ‚ç‚¹42æ·»åŠ EmptyImageè¾“å…¥")
        
        # åˆ é™¤èŠ‚ç‚¹146ï¼ˆImageStitchï¼‰ï¼Œå› ä¸ºå®ƒçš„è¾“å…¥å·²ç»è¢«åˆ é™¤
        if "146" in workflow:
            del workflow["146"]
            print("âœ… åˆ é™¤èŠ‚ç‚¹146ï¼ˆImageStitchï¼‰")
        
        # ä¿®å¤å…¶ä»–èŠ‚ç‚¹å¯¹èŠ‚ç‚¹146çš„å¼•ç”¨
        for node_id, node in workflow.items():
            if "inputs" in node:
                for input_name, input_value in node["inputs"].items():
                    if isinstance(input_value, list) and len(input_value) >= 1:
                        referenced_node = str(input_value[0])
                        if referenced_node == "146":
                            # å°†å¼•ç”¨é‡å®šå‘åˆ°èŠ‚ç‚¹42
                            node["inputs"][input_name] = ["42", 0]
                            print(f"âœ… å°†èŠ‚ç‚¹ {node_id} çš„ {input_name} å¼•ç”¨é‡å®šå‘åˆ°èŠ‚ç‚¹42")
        
        return workflow
